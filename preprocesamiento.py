# -*- coding: utf-8 -*-
"""preprocesamiento.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uXgm7ZKHVn2Mdy9gTPhLbervvvoJ2gB4
"""

!pip install unidecode

from google.colab import drive
import pickle
from pickle import load
import numpy as np
from unidecode import unidecode
import re

drive.mount('/content/drive')

# Ruta del archivo de texto
ruta_archivo_txt = '/content/drive/MyDrive/Codigos/Machine Learning /Proyecto traductor/dataset2.txt'

# Leer el contenido del archivo de texto
with open(ruta_archivo_txt, 'r', encoding='utf-8') as archivo_txt:
    lineas = archivo_txt.readlines()

# Crear array de arrays con las palabras en inglés y español
datos = []
for linea in lineas:
    ingles, espanol = map(str.strip, linea.split('\t'))
    datos.append([unidecode(ingles), unidecode(espanol)])

def preprocessing(text):
    new_text = re.sub(r'[^\w\s]', '', text) # Eliminar signos de puntuación
    new_text = unidecode(new_text)          # Eliminar acentos
    new_text = new_text.lower()             # Convertir a minúsculas

    # Eliminar palabras duplicadas
    words = new_text.split()
    unique_words = list(set(words))
    new_text = ' '.join(unique_words)
    return new_text


# Ruta del archivo de texto
ruta_archivo_txt = '/content/drive/MyDrive/Codigos/Machine Learning /Proyecto traductor/dataset2.txt'

# Leer el contenido del archivo de texto
with open(ruta_archivo_txt, 'r', encoding='utf-8') as archivo_txt:
    lineas = archivo_txt.readlines()

# Crear array de arrays con las palabras en ingles y español
datos = []

for linea in lineas:
    ingles, espanol = map(str.strip, linea.split('\t'))
    ingles, espanol = preprocessing(ingles), preprocessing(espanol)
    datos.append([ingles, espanol])

datos = np.array(datos)

# Ruta del archivo pickle
ruta_archivo_pkl = '/content/drive/MyDrive/Codigos/Machine Learning /Proyecto traductor/dataset2.pkl'

# Guardar el array de arrays en el archivo pickle
with open(ruta_archivo_pkl, 'wb') as archivo_pkl:
    pickle.dump(datos, archivo_pkl)

dataset = load(open(ruta_archivo_pkl, 'rb'))
print(dataset[-1])
print(len(dataset))